{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4_Session_5_Iteration4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=20, kernel_size=(3,3), padding=0, stride=1), \n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU()\n",
        "        )#Output=26 RF=3X3 [RFin + (Ksize-1 * JMPin) => 1+(3-1)*1 =3]  :JMPin=1, Jout= JMPin X s = 1\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=20, out_channels=16, kernel_size=(3,3), padding=0, stride=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()    \n",
        "        )#Output=24 RF=5X5  [RFin + (Ksize-1 * JMPin) => 3+(3-1)*1 =5] :JMPin=1, Jout =JMPin X s =1\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)#Output=12 RF=6X6 [RFin + (Ksize-1 * JMPin) => 5+(2-1)*1 =6] :JMPin=1, Jout=  JMPin X s =2\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=0, stride=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )#Output=10 RF=10X10 [RFin + (Ksize-1 * JMPin) => 6+(3-1)*2 =10] : Jout= JMPin X s = 2X1 :JMPin=2, Jout= JMPin X s = 2X1=2\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) #Output=5 RF=12[RFin + (Ksize-1 * JMPin) => 10+(2-1)*2 =12]  :JMPin=2, Jout =JMPin X s = 2X2 =4\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=0, stride=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()            \n",
        "        )#Output=3 RF= 20[RFin + (Ksize-1 * JMPin) => 12+(3-1)*4 =20] :JMPin=4, Jout =JMPin X s = 4X1=4\n",
        "\n",
        "        \n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(3,3), padding=0, stride=1),\n",
        "            #nn.ReLU()\n",
        "        )#Output=1 RF=28 [RFin + (Ksize-1 * JMPin) => 20+(3-1)*4 =28]  :JMPin=4, Jout=JMPin X s = 4X1=4\n",
        "     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)        \n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdydjYTZFyi3",
        "outputId": "f46cc506-fe22-48db-9865-da3d47e58da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 20, 26, 26]             200\n",
            "       BatchNorm2d-2           [-1, 20, 26, 26]              40\n",
            "              ReLU-3           [-1, 20, 26, 26]               0\n",
            "            Conv2d-4           [-1, 16, 24, 24]           2,896\n",
            "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
            "              ReLU-6           [-1, 16, 24, 24]               0\n",
            "         MaxPool2d-7           [-1, 16, 12, 12]               0\n",
            "            Conv2d-8           [-1, 16, 10, 10]           2,320\n",
            "       BatchNorm2d-9           [-1, 16, 10, 10]              32\n",
            "             ReLU-10           [-1, 16, 10, 10]               0\n",
            "        MaxPool2d-11             [-1, 16, 5, 5]               0\n",
            "           Conv2d-12             [-1, 16, 3, 3]           2,320\n",
            "      BatchNorm2d-13             [-1, 16, 3, 3]              32\n",
            "             ReLU-14             [-1, 16, 3, 3]               0\n",
            "           Conv2d-15             [-1, 10, 1, 1]           1,450\n",
            "================================================================\n",
            "Total params: 9,322\n",
            "Trainable params: 9,322\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.58\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.62\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "Train_Loss=[]\n",
        "Train_Accuracy=[]\n",
        "Test_Loss=[]\n",
        "Test_Accuracy=[]\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct_train=0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        Train_Loss.append(loss.item())\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct_train += pred.eq(target.view_as(pred)).sum().item()\n",
        "        Train_Accuracy.append(100.00 *correct_train/len(train_loader.dataset))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #pbar.set_description(desc= f'TRAINING Loss={loss.item()} batch_id={batch_idx}')\n",
        "        \n",
        "        ##Added detailed percentage:\n",
        "        pbar.set_description(desc= f'TRAIN Loss={loss.item()} batch_id={batch_idx} Correct={correct_train} / {len(train_loader.dataset)} TRAIN ACCURACY={100.00 *correct_train/len(train_loader.dataset)}')\n",
        "     \n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss=F.nll_loss(output, target)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            \n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    Test_Loss.append(test_loss)\n",
        "    Test_Accuracy.append(100. * correct / len(test_loader.dataset))\n",
        "    print('\\nTEST: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab_type": "code",
        "outputId": "621087e7-f711-45fa-9bdf-56b0131ae1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "df_Test_Train_Analysis=pd.DataFrame(columns=['EPOCH','Test_Acc','Train_Acc','Acc_Diff'])\n",
        "print(df_Test_Train_Analysis.shape)\n",
        "for epoch in range(1, 15):\n",
        "    print('EPOCH #',epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    print('----------------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(0, 4)\n",
            "EPOCH # 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "TRAIN Loss=0.1261681318283081 batch_id=468 Correct=56690 / 60000 TRAIN ACCURACY=94.48333333333333: 100%|██████████| 469/469 [00:16<00:00, 28.32it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0737, Accuracy: 9782/10000 (97.82%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.053370144218206406 batch_id=468 Correct=59004 / 60000 TRAIN ACCURACY=98.34: 100%|██████████| 469/469 [00:16<00:00, 28.82it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0501, Accuracy: 9847/10000 (98.47%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.016645709052681923 batch_id=468 Correct=59261 / 60000 TRAIN ACCURACY=98.76833333333333: 100%|██████████| 469/469 [00:16<00:00, 28.76it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0421, Accuracy: 9852/10000 (98.52%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.047489527612924576 batch_id=468 Correct=59374 / 60000 TRAIN ACCURACY=98.95666666666666: 100%|██████████| 469/469 [00:16<00:00, 28.77it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0395, Accuracy: 9878/10000 (98.78%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.02871301770210266 batch_id=468 Correct=59471 / 60000 TRAIN ACCURACY=99.11833333333334: 100%|██████████| 469/469 [00:16<00:00, 28.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0487, Accuracy: 9847/10000 (98.47%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.10962352156639099 batch_id=468 Correct=59524 / 60000 TRAIN ACCURACY=99.20666666666666: 100%|██████████| 469/469 [00:16<00:00, 28.76it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0376, Accuracy: 9880/10000 (98.80%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.009714360348880291 batch_id=468 Correct=59594 / 60000 TRAIN ACCURACY=99.32333333333334: 100%|██████████| 469/469 [00:16<00:00, 28.78it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0316, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.009134541265666485 batch_id=468 Correct=59639 / 60000 TRAIN ACCURACY=99.39833333333333: 100%|██████████| 469/469 [00:16<00:00, 28.74it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0327, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.014771307818591595 batch_id=468 Correct=59703 / 60000 TRAIN ACCURACY=99.505: 100%|██████████| 469/469 [00:16<00:00, 28.83it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0301, Accuracy: 9911/10000 (99.11%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.024922087788581848 batch_id=468 Correct=59718 / 60000 TRAIN ACCURACY=99.53: 100%|██████████| 469/469 [00:16<00:00, 28.75it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0290, Accuracy: 9908/10000 (99.08%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.007528156042098999 batch_id=468 Correct=59742 / 60000 TRAIN ACCURACY=99.57: 100%|██████████| 469/469 [00:16<00:00, 28.86it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0283, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.00931653380393982 batch_id=468 Correct=59769 / 60000 TRAIN ACCURACY=99.615: 100%|██████████| 469/469 [00:16<00:00, 28.92it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0308, Accuracy: 9902/10000 (99.02%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.010672171600162983 batch_id=468 Correct=59812 / 60000 TRAIN ACCURACY=99.68666666666667: 100%|██████████| 469/469 [00:16<00:00, 29.21it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0320, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "EPOCH # 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN Loss=0.01235741376876831 batch_id=468 Correct=59801 / 60000 TRAIN ACCURACY=99.66833333333334: 100%|██████████| 469/469 [00:16<00:00, 29.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TEST: Average loss: 0.0283, Accuracy: 9909/10000 (99.09%)\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-JaAcAgYkK0",
        "colab_type": "text"
      },
      "source": [
        "#Goal\t\n",
        "We intend to tackle the Overfitting problem by including batch normalization in the model.\n",
        "\n",
        "#Params\t\n",
        "9322\n",
        "\n",
        "#WITH 20 EPOCHS\n",
        "#Best Train Accuracy\t\n",
        "99.4%\n",
        "\n",
        "#Best Test Accuracy\t\n",
        "99.24%\n",
        "#Observation/ Analysis/Conclusion\t\n",
        "We used Batch Normalization in this Model to tackle the ovefitting issue.\n",
        "This Model is GREAT. For all the Epochs (except for 2) the difference between Training and Test Accuracy is very small.\n",
        "Why the model is good?\n",
        "The model is very good  because of the CONSISTENCY in the Training and Test Accuracy difference.\n",
        "\n",
        "#WITH 15 EPOCHS\n",
        "\n",
        "#Best Train Accuracy\t\n",
        "99.68%\n",
        "\n",
        "#Best Test Accuracy\t\n",
        "99.1%\n",
        "#Observation/ Analysis/Conclusion\t\n",
        "The model does not reach the Target accuracy for almost all the EPOCHs.\n",
        "The model is consistent for last few EPOCHS, i.e.the difference between Training and Test Accuracy is not large but still, hence even the Model suffers from Overfitting Problem , but it being consistent leads to conclusion that we could push the model further to learn better.\n",
        "Next optimization technique we would use is Drop Out method.\n",
        "\n",
        "Drop out helps to reduce the train and test accuracy gaps, hence we would give it a shot to verify if this method could help us to overcome Overfitting Problem in the Model\n",
        "\n",
        "\n",
        "#Comment\t\n",
        "This means we must continue to train the model to achive better accuracy."
      ]
    }
  ]
}